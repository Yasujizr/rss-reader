No-download idea

The idea is to not download articles/feeds. Just store urls and titles. Like reading list.

Then fetch on demand, and cleanup on demand.

More like a content script.

Almost no local storage.

There is no real point to storing full text. The only benefit is offline mode.

The question is whether this kind of offline support is really worthwhile. For one,
it is stupid to partially support it. Either go the full way or do not bother.

One of the problems with the caching is that it feels like re-creation of the entire
browser. Dealing with url resolution and parsing and safety and sandboxing and
sanitizing and all this junk.

If online, the keys are speed (page fetch and display speed), and just maintaining
a list of whats left to read and whats already been read.


----------------------

Continuing on these lines is the question of why I am converting XML to json to store
in indexedDB in the first place. Why not just store the XML?